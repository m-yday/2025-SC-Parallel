[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistical Computing Practicals",
    "section": "",
    "text": "Welcome!\nHello :)",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "parallel.html",
    "href": "parallel.html",
    "title": "1  Parallel",
    "section": "",
    "text": "# library(quarto)\n# library(projrsimple)\n# library(remotes)\nlibrary(tidyverse)\nlibrary(foreach)\nlibrary(doParallel)\nlibrary(knitr)\n\n\nQuestion 1\n\nn1 &lt;- 100 # sample size\n \nforeach(i=1:100, .combine = \"rbind\") %do% {\n  samp &lt;- rexp(n1,1)\n  cbind(mean=mean(samp), variance=var(samp))\n} |&gt; round(3) |&gt; head(10) |&gt; \n  kable(caption = \"First 10 of 100 sets of the measured bootstrap statistics.\")\n\n\nFirst 10 of 100 sets of the measured bootstrap statistics.\n\n\nmean\nvariance\n\n\n\n\n0.942\n0.718\n\n\n1.185\n1.257\n\n\n0.945\n1.008\n\n\n1.155\n1.134\n\n\n1.010\n1.661\n\n\n1.068\n0.901\n\n\n1.026\n0.989\n\n\n0.909\n0.529\n\n\n0.991\n1.081\n\n\n0.974\n0.764\n\n\n\n\n\n\n\nQuestion 2\nSequential results:\n\nn2 &lt;- 50 # bootstrap sample size\nb2 &lt;- 1000 # bootstraps per iteration\niter &lt;- 100 # iterations\n\n#num of cores to use in parallelisation.\ncores &lt;- detectCores() - 1 # leaves one core idle, to minimise system slowdowns\n\nboot_q2 &lt;- function(){\n  sample(x=galaxies,size=n2,replace=T) |&gt; median()\n}\n\n# sequential\nt2_seq &lt;- system.time(\n  foreach(i=1:iter,.packages = 'MASS',.combine='c') %do% {\n    replicate(b2,boot_q2())\n  })\n\n#create parallel cluster\ncl &lt;- makeCluster(cores) \nregisterDoParallel(cl)\n\n# parallel\nt2_par &lt;- system.time({\n  foreach(i=1:iter,.packages = c('MASS'),.combine='c') %dopar% {\n    replicate(b2,boot_q2())\n  }})\n\n#close parallel cluster\nstopCluster(cl)\n\n\nrbind(\"Sequential\"=t2_seq[1:3],\n      \"Parallel\"=t2_par[1:3]) |&gt;\n  kable(\n    caption=\"Execution times for finding 100,000 bootstrapped medians.\",\n    col.names=c(\"User\", \"System\", \"Total Elapsed\"),\n    row.names=1)\n\n\nExecution times for finding 100,000 bootstrapped medians.\n\n\n\nUser\nSystem\nTotal Elapsed\n\n\n\n\nSequential\n1.403\n0.020\n1.427\n\n\nParallel\n0.020\n0.005\n0.194\n\n\n\n\n\n\n\nQuestion 3\n\nn3 &lt;- 50\nB3 &lt;- 10000\nalpha &lt;- 0.05\nconfidence &lt;- (1-alpha)*100 # confidence in %\n\nlower_index &lt;- B3*(alpha)/2\nupper_index &lt;- B3-lower_index\n\nsample3 &lt;- rexp(n3,1)\n\ncl &lt;- makeCluster(cores) \n\nregisterDoParallel(cl)\nclusterExport(cl=cl, varlist=c(\"sample3\",\"n3\"))\n\nbootstrap3 &lt;- foreach(\n  i=1:B3, \n  .combine=(\"rbind\")\n  ) %dopar% {\n    sample(x=sample3,size=n3,replace=T) |&gt; \n      sort()\n} |&gt; as.matrix()\nstopCluster(cl)\n\nmeans3 &lt;- apply(bootstrap3,1,'mean')\nvars3  &lt;- apply(bootstrap3,1,'var')\n\noriginal_mean3 &lt;- mean(sample3)\nstat_mean3 &lt;- mean(means3)\nstat_var3 &lt;- var(means3)\n\n\ndist3 &lt;- qnorm(alpha/2,0,1,lower.tail=F)*sqrt(vars3/n3)\nlCI &lt;- means3 - dist3\nuCI &lt;- means3 + dist3\ncoverage &lt;- sum(original_mean3&gt;lCI & original_mean3&lt;=uCI)/B3\n\nThe coverage of the 95% confidence interval of means is 0.924.\n\n\nQuestion 4\n\n# cl&lt;- makeCluster(cores)\n# registerDoParallel(cl)\n\nset.seed(1234)\nforeach(i=irnorm(5,0,1,count=3)) %do% {\n  max(i)\n} |&gt; print()\n\n[[1]]\n[1] 1.084441\n\n[[2]]\n[1] 0.5060559\n\n[[3]]\n[1] 0.9594941\n\n#stopCluster(cl)\n\n\n\nQuestion 5\n\nset.seed(1234)\ncl &lt;- makeCluster(cores)\n\n\n# irnorm(n=5,mean=57,sd=3, count=100)\n# \n# \n# iterator &lt;- irnorm(n=5,mean=57,sd=3,count=100)\n# nextElem(iterator)\n# \n# parLapply(cl=cl, X=, fun=\"max\", chunk.size=200)\n# \n# iterator &lt;- irnorm(n=5,mean=57,sd=3,count=100)\n# max(nextElem(iterator))\n# \n# lapply(X=replicate(100,rnorm(5,57,3)),FUN='max')\n\nstopCluster(cl)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Parallel</span>"
    ]
  }
]